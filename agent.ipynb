{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap step>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "# 导入基础库\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "# 导入pytorch库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# 导入图像处理库\n",
    "import timm\n",
    "# 导入绘图库\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('client')\n",
    "# # 导入julia\n",
    "import julia\n",
    "from julia import Main as env\n",
    "env.include(\"environment03.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义网络常数\n",
    "LOG_STD_MAX = 2     # 最大标准差\n",
    "LOG_STD_MIN = -20   # 最小标准差\n",
    "\n",
    "## 自定义特征提取器\n",
    "class StateFeatureExtractor(nn.Module):\n",
    "    '''\n",
    "    特征提取器, 从state中提取特征向量, 并作为动作价值函数以及策略函数的输入\n",
    "    out_channels: 输出通道数\n",
    "    gm_size: global_map的形状。gm_size = [通道数，维度，维度，维度]\n",
    "    lm_size: local_map的形状。lm_size = [通道数，维度，维度]\n",
    "    cs_size: cs的形状(cs是一个向量)。cs_size = 维度\n",
    "    gm_output_dim: self.gm_extractor的输出维度\n",
    "    '''\n",
    "    def __init__(self, gm_out_channels, lm_out_channels, gm_size, lm_size, cs_size, gm_output_dim = 128, lm_output_dim = 512, cs_output_dim = 16, output_dim = 512):\n",
    "        super(StateFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.gm_in_channels = gm_size[0]    # global_map通道数\n",
    "        self.lm_in_channels = lm_size[0]    # local_map通道数\n",
    "        self.gm_volume = gm_size[1] * gm_size[2] * gm_size[3]   # global_map通道维度之外的三个维度的形状\n",
    "        self.lm_area = lm_size[1] * lm_size[2]  # local_map通道维度之外的两个维度的形状\n",
    "        self.gm_out_channels = gm_out_channels    # global_map输出通道数\n",
    "        self.lm_out_channels = lm_out_channels  # local_map输出通道数\n",
    "        self.cs_dim = cs_size       # cs(刀具位置和姿态)的维度\n",
    "        self.gm_output_dim = gm_output_dim  # self.gm_extractor的输出维度\n",
    "        self.lm_output_dim = lm_output_dim  # self.lm_extractor的输出维度\n",
    "        self.cs_output_dim = cs_output_dim  # self.cs_extractor的输出维度\n",
    "        self.output_dim = output_dim        # self.collective_extractor的输出维度\n",
    "\n",
    "        #! 定义global_map特征提取卷积层\n",
    "        self.gm_extractor = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=self.gm_in_channels, out_channels=self.gm_out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=self.gm_out_channels, out_channels=self.gm_out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.gm_out_channels * self.gm_volume, out_features=self.gm_output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #! 定义local_map特征提取卷积层\n",
    "        self.lm_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.lm_in_channels, out_channels=self.lm_out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=self.lm_out_channels, out_channels=self.lm_out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.lm_out_channels * self.lm_area, self.lm_output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #! 定义cs特征提取层\n",
    "        self.cs_extractor = nn.Sequential(\n",
    "            nn.Linear(self.cs_dim, self.cs_output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #! 整合三个特征提取层\n",
    "        self.collective_extractor = nn.Sequential(\n",
    "            nn.Linear(self.gm_output_dim + self.lm_output_dim + self.cs_output_dim, self.output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        gm = x[0]\n",
    "        lm = x[1]\n",
    "        cs = x[2]\n",
    "        gm = self.gm_extractor(gm)\n",
    "        lm = self.lm_extractor(lm)\n",
    "        cs = self.cs_extractor(cs)\n",
    "        x = torch.cat((gm, lm, cs), dim=1)\n",
    "        x = self.collective_extractor(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "## 自定义动作价值函数\n",
    "class QNetWork(nn.Module):\n",
    "    '''\n",
    "    动作价值函数, 根据状态(state)输入和动作(action)输入, 输出动作价值\n",
    "    if_feature_extractor: 是否使用特征提取器。True: 使用特征提取器, False: 不使用特征提取器。默认不使用特征提取器\n",
    "    state_dim: 状态维度。如果采用特征提取器, 则特征提取器的输出维度output_dim=state_dim\n",
    "    action_dim: 动作维度。action_dim = [x位置变化, y位置变化, z位置变化, theta角度变化, phi角度变化, 主轴转速的变化, 进给速度的变化]\n",
    "    output_dim: 输出维度, 固定为1, 输出奖励值\n",
    "    feature_dim1: 第一个隐藏层维度\n",
    "    feature_dim2: 第二个隐藏层维度\n",
    "    '''\n",
    "    def __init__(self, if_feature_extractor = True, features_extractor: StateFeatureExtractor = None, state_dim = 512, action_dim = 7, output_dim = 1, hidden_dim1 = 256, hidden_dim2 = 128):\n",
    "        super(QNetWork, self).__init__()\n",
    "\n",
    "        self.if_feature_extractor = if_feature_extractor\n",
    "        self.features_extractor = features_extractor\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "\n",
    "        #! Q值网络\n",
    "        self.q_network = nn.Sequential(\n",
    "            nn.Linear(self.state_dim + self.action_dim, self.hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim1, self.hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim2, self.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        if self.if_feature_extractor:   # 采用特征提取器, 将state转换成特征向量state\n",
    "            #* 动作价值函数与策略函数共用一个特征提取器\n",
    "            with torch.no_grad():\n",
    "                state = self.features_extractor(state)\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        x = self.q_network(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "## 自定义策略函数\n",
    "class PolicyNetWork(nn.Module):\n",
    "    '''\n",
    "    策略函数, 根据状态(state)输入, 输出动作(action)概率\n",
    "    if_feature_extractor: 是否使用特征提取器。True: 使用特征提取器, False: 不使用特征提取器。默认不使用特征提取器\n",
    "    state_dim: 状态维度\n",
    "    action_dim: 动作维度\n",
    "    feature_dim1: 第一个隐藏层维度\n",
    "    feature_dim2: 第二个隐藏层维度\n",
    "    '''\n",
    "    def __init__(self, if_feature_extractor = True, features_extractor: StateFeatureExtractor = None, state_dim = 512, action_dim = 7, hidden_dim = 256, output_dim = 128):\n",
    "        super(PolicyNetWork, self).__init__()\n",
    "\n",
    "        self.if_feature_extractor = if_feature_extractor\n",
    "        self.features_extractor = features_extractor\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        #! 策略网络\n",
    "        self.policy_dist = nn.Sequential(\n",
    "            nn.Linear(self.state_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #! 输出均值和标准差\n",
    "        # TODO：https://arxiv.org/abs/2005.05719 提出一种根据状态的采样策略，可以尝试使用\n",
    "        self.log_std = nn.Linear(self.output_dim, self.action_dim)\n",
    "        self.mu = nn.Linear(self.output_dim, self.action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        '''\n",
    "        前向传播\n",
    "        '''\n",
    "        # 0. 特征提取器提取特征\n",
    "        if self.if_feature_extractor:\n",
    "            state = self.features_extractor(state)\n",
    "        # 1. 通过policy网络得到log_std和mu\n",
    "        x = self.policy_dist(state)\n",
    "        mu = self.mu(x)\n",
    "        log_std = self.log_std(x)\n",
    "        log_std = torch.clamp(log_std, LOG_STD_MIN, LOG_STD_MAX)    # 限制log_std的范围\n",
    "        std = torch.exp(log_std)    # 得到真正的标准差\n",
    "        # 2. 通过std和mu创建高斯分布\n",
    "        dist = torch.distributions.Normal(mu, std)\n",
    "        # 3. 从高斯分布中取样得到动作\n",
    "        u = dist.rsample()\n",
    "        action = torch.tanh(u)  # 将动作限制在[-1， 1]之间\n",
    "        # 4. 计算动作分布的标准差并返回对数标准差的和\n",
    "        log_prob = dist.log_prob(u)\n",
    "        log_prob -= torch.log(1 - action ** 2 + 1e-6)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "        return action, log_prob\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        采样动作\n",
    "        '''\n",
    "        # 0. 特征提取器提取特征\n",
    "        if self.if_feature_extractor:\n",
    "            state = self.features_extractor(state)\n",
    "        # 1. 通过policy网络得到log_std和mu\n",
    "        x = self.policy_dist(state)\n",
    "        mu = self.mu(x)\n",
    "        return torch.tanh(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 经验回放缓冲区\n",
    "# TODO: 优化经验回放缓冲区\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state','reward', 'done', 'action', 'next_state'))\n",
    "\n",
    "#// class Memory:\n",
    "#//     def __init__(self, memory_size):\n",
    "#//         self.memory_size = memory_size\n",
    "#//         self.memory = []\n",
    "#//     def add(self, *transition):\n",
    "#//         self.memory.append(Transition(*transition))\n",
    "#//         if len(self.memory) > self.memory_size:\n",
    "#//             self.memory.pop(0)\n",
    "#//         assert len(self.memory) <= self.memory_size\n",
    "#//     def sample(self, batch_size = 256):\n",
    "#//         return random.sample(self.memory, batch_size)\n",
    "#//     def __len__(self):\n",
    "#//         return len(self.memory)\n",
    "\n",
    "class ReplayBuffer:\n",
    "    '''\n",
    "    经验回放缓冲区\n",
    "    memory_size: 缓冲区大小\n",
    "    batch_size: 批次大小\n",
    "    '''\n",
    "    def __init__(self, memory_size = 1000000, batch_size = 256):\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = []\n",
    "\n",
    "    def add(self, state, reward, done, action, next_state):\n",
    "        self.memory.append(Transition(state, reward, done, action, next_state))\n",
    "        if len(self.memory) > self.memory_size:\n",
    "            self.memory.pop(0)\n",
    "        assert len(self.memory) <= self.memory_size\n",
    "\n",
    "    def sample(self):\n",
    "        return random.sample(self.memory, self.batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAC算法\n",
    "class SAC:\n",
    "    '''\n",
    "    learning_rate: 学习率\n",
    "    tau: 软更新参数\n",
    "    gamma: 折扣因子\n",
    "    buffer_size: 经验回放缓冲区大小\n",
    "    batch_size: 训练batch大小\n",
    "    if_feature_extractor: 是否使用特征提取器\n",
    "    gm_out_channels: global_map输出通道数\n",
    "    lm_out_channels: local_map输出通道数\n",
    "    gm_size: global_map的形状。gm_size = [通道数，维度，维度，维度]\n",
    "    lm_size: local_map的形状。lm_size = [通道数，维度，维度]\n",
    "    cs_size: cs的形状(cs是一个向量)。cs_size = 维度\n",
    "    gm_output_dim: self.gm_extractor的输出维度\n",
    "    lm_output_dim: self.lm_extractor的输出维度\n",
    "    cs_output_dim: self.cs_extractor的输出维度\n",
    "    features_dim: 特征提取器的输出维度\n",
    "    action_dim: 动作维度\n",
    "    q_hidden_dim1: Q网络第一个隐藏层维度\n",
    "    q_hidden_dim2: Q网络第二个隐藏层维度\n",
    "    p_hidden_dim1: 策略网络第一个隐藏层维度\n",
    "    p_hidden_dim2: 策略网络第二个隐藏层维度\n",
    "    ent_coef: 熵系数\n",
    "    '''\n",
    "    def __init__(\n",
    "            self,\n",
    "            env,\n",
    "            learning_rate = 0.003,\n",
    "            tau = 0.005,\n",
    "            gamma = 0.99,\n",
    "            buffer_size = 1000000,\n",
    "            batch_size = 256,\n",
    "            if_feature_extractor = False,\n",
    "            gm_out_channels = 2,\n",
    "            lm_out_channels = 18,\n",
    "            gm_size = [2, 10, 10, 10],\n",
    "            lm_size = [18, 75, 75],\n",
    "            cs_size = 9,\n",
    "            gm_output_dim = 128,\n",
    "            lm_output_dim = 512,\n",
    "            cs_output_dim = 16,\n",
    "            features_dim = 512,\n",
    "            action_dim = 7,\n",
    "            q_hidden_dim1 = 256,\n",
    "            q_hidden_dim2 = 128,\n",
    "            p_hidden_dim1 = 256,\n",
    "            p_hidden_dim2 = 128,\n",
    "            ent_coef = 0.1\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.if_feature_extractor = if_feature_extractor\n",
    "        self.features_dim = features_dim    # 特征提取器的输出维度，同时也是Q网络和策略网络的状态输入维度\n",
    "        self.action_dim = action_dim        # 动作维度\n",
    "        self.q_hidden_dim1 = q_hidden_dim1  # Q网络第一个隐藏层维度\n",
    "        self.q_hidden_dim2 = q_hidden_dim2\n",
    "        self.p_hidden_dim1 = p_hidden_dim1\n",
    "        self.p_hidden_dim2 = p_hidden_dim2\n",
    "        self.target_entropy = -self.action_dim  # 目标熵\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # 使用特征提取器\n",
    "        if if_feature_extractor:\n",
    "            self.gm_out_channels = gm_out_channels\n",
    "            self.lm_out_channels = lm_out_channels\n",
    "            self.gm_size = gm_size\n",
    "            self.lm_size = lm_size\n",
    "            self.cs_size = cs_size\n",
    "            self.gm_output_dim = gm_output_dim\n",
    "            self.lm_output_dim = lm_output_dim\n",
    "            self.cs_output_dim = cs_output_dim\n",
    "            self.features_extractor = StateFeatureExtractor(gm_output_channels=self.gm_out_channels, lm_out_channels=self.lm_out_channels, \n",
    "                                                            gm_size=self.gm_size, lm_size=self.lm_size, cs_size=self.cs_size, \n",
    "                                                            gm_output_dim=self.gm_output_dim, lm_output_dim=self.lm_output_dim, cs_output_dim=self.cs_output_dim, output_dim=self.features_dim).to(self.device)\n",
    "        else:\n",
    "            self.features_extractor = None\n",
    "\n",
    "        # 定义Q网络\n",
    "        self.q1 = QNetWork(if_feature_extractor=self.if_feature_extractor, features_extractor=self.features_extractor, \n",
    "                      state_dim=self.features_dim, action_dim=self.action_dim, hidden_dim1=self.q_hidden_dim1, hidden_dim2=self.q_hidden_dim2).to(self.device)\n",
    "        self.q2 = QNetWork(if_feature_extractor=self.if_feature_extractor, features_extractor=self.features_extractor,\n",
    "                      state_dim=self.features_dim, action_dim=self.action_dim, hidden_dim1=self.q_hidden_dim1, hidden_dim2=self.q_hidden_dim2).to(self.device)\n",
    "        self.q1_target = QNetWork(if_feature_extractor=self.if_feature_extractor, features_extractor=self.features_extractor,\n",
    "                             state_dim=self.features_dim, action_dim=self.action_dim, hidden_dim1=self.q_hidden_dim1, hidden_dim2=self.q_hidden_dim2).to(self.device)\n",
    "        self.q2_target = QNetWork(if_feature_extractor=self.if_feature_extractor, features_extractor=self.features_extractor,\n",
    "                             state_dim=self.features_dim, action_dim=self.action_dim, hidden_dim1=self.q_hidden_dim1, hidden_dim2=self.q_hidden_dim2).to(self.device)\n",
    "        self.q1_opt = optim.Adam(self.q1.parameters(), lr=self.learning_rate)   # 定义Q网络优化器\n",
    "        self.q2_opt = optim.Adam(self.q2.parameters(), lr=self.learning_rate)   # 定义Q网络优化器\n",
    "\n",
    "        # 定义策略网络\n",
    "        self.policy_net = PolicyNetWork(state_dim=self.features_dim, action_dim=self.action_dim, \n",
    "                                        if_feature_extractor=self.if_feature_extractor, \n",
    "                                        hidden_dim=self.p_hidden_dim1, output_dim=self.p_hidden_dim2).to(self.device)\n",
    "        if self.if_feature_extractor:   # 采用特征提取器, 则策略网络和特征提取器共同训练\n",
    "            self.policy_opt = optim.Adam(list(self.features_extractor.parameters()) + list(self.policy_net.parameters()), lr=self.learning_rate)\n",
    "        else:\n",
    "            self.policy_opt = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)   # 定义策略网络优化器\n",
    "        \n",
    "        # 定义经验回放缓冲区\n",
    "        self.replay_buffer = ReplayBuffer(self.buffer_size, self.batch_size)\n",
    "\n",
    "        # 定义温度\n",
    "        self.log_ent_coef = torch.tensor([0.0]).to(self.device).requires_grad_()\n",
    "        self.ent_coef_opt = optim.Adam([self.log_ent_coef], lr=self.learning_rate)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = torch.FloatTensor([state]).to(self.device)\n",
    "        action, _ = self.policy_net(state)\n",
    "        return action.cpu().detach().numpy()\n",
    "    \n",
    "    def eval_action(self, state):\n",
    "        state = torch.FloatTensor([state]).to(self.device)\n",
    "        action = self.policy_net.get_action(state)\n",
    "        return action.cpu().detach().numpy()\n",
    "\n",
    "    def store(self, state, reward, done, action, next_state):\n",
    "        state = torch.FloatTensor(state)\n",
    "        reward = torch.Tensor([reward])\n",
    "        done = torch.Tensor([done])\n",
    "        action = np.array([action])\n",
    "        action = torch.Tensor(action)\n",
    "        next_state = torch.FloatTensor(next_state)\n",
    "        self.replay_buffer.add(state, reward, done, action, next_state)\n",
    "\n",
    "    def unpack(self, batch):\n",
    "        batch = Transition(*zip(*batch))\n",
    "        states = torch.cat(batch.state).view(self.batch_size, self.features_dim).to(self.device)\n",
    "        rewards = torch.cat(batch.reward).view(self.batch_size, 1).to(self.device)\n",
    "        dones = torch.cat(batch.done).view(self.batch_size, 1).to(self.device)\n",
    "        actions = torch.cat(batch.action).view(-1, self.action_dim).to(self.device)\n",
    "        next_states = torch.cat(batch.next_state).view(self.batch_size, self.features_dim).to(self.device)\n",
    "        return states, rewards, dones, actions, next_states\n",
    "\n",
    "    def train(self):\n",
    "        '''\n",
    "        训练函数\n",
    "        '''\n",
    "        # 0. 经验回放缓冲区中取样\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        batch = self.replay_buffer.sample()\n",
    "        state, reward, done, action, next_state = self.unpack(batch)\n",
    "\n",
    "        # 1. 策略网络根据state预测动作\n",
    "        action_pi, log_prob = self.policy_net(state)\n",
    "        # log_prob = log_prob.reshape(-1, 1) \n",
    "\n",
    "        # 2. 更新温度\n",
    "        ent_coef = torch.exp(self.log_ent_coef.detach())\n",
    "        ent_coef_loss = -(self.log_ent_coef * (log_prob + self.target_entropy).detach()).mean()\n",
    "        self.ent_coef_opt.zero_grad()\n",
    "        ent_coef_loss.backward()\n",
    "        self.ent_coef_opt.step()\n",
    "         \n",
    "        # 3. 更新状态价值函数\n",
    "        # 3.1 计算目标Q值target\n",
    "        with torch.no_grad():   # 不更新q1_target和q2_target\n",
    "            next_action, next_log_prob = self.policy_net(next_state)\n",
    "            q1_target = self.q1_target(next_state, next_action)\n",
    "            q2_target = self.q2_target(next_state, next_action)\n",
    "            q_target = torch.min(q1_target, q2_target)\n",
    "            #! 这里next_log_prob的维度可能出现问题\n",
    "            target_q = reward + self.gamma * (1 - done) * (q_target - ent_coef * next_log_prob)\n",
    "\n",
    "        # 3.2 计算q网络的当前q值current_q1, current_q2\n",
    "        current_q1 = self.q1(state, action)\n",
    "        current_q2 = self.q2(state, action)\n",
    "\n",
    "        # 3.3 计算q网络的损失函数\n",
    "        q1_loss = F.mse_loss(current_q1, target_q)\n",
    "        q2_loss = F.mse_loss(current_q2, target_q)\n",
    "\n",
    "        # 3.4 更新q网络\n",
    "        self.q1_opt.zero_grad()\n",
    "        q1_loss.backward()\n",
    "        self.q1_opt.step()\n",
    "        self.q2_opt.zero_grad()\n",
    "        q2_loss.backward()\n",
    "        self.q2_opt.step()\n",
    "\n",
    "        # 4. 更新策略网络\n",
    "        # 4.1 计算策略网络的损失函数\n",
    "        q1 = self.q1(state, action_pi)\n",
    "        q2 = self.q2(state, action_pi)\n",
    "        q_min = torch.min(q1, q2)\n",
    "        policy_loss = (ent_coef * log_prob - q_min).mean()\n",
    "\n",
    "        # 4.2 更新策略网络\n",
    "        self.policy_opt.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.policy_opt.step()\n",
    "\n",
    "        # 5. 软更新目标Q网络\n",
    "        for param, target_param in zip(self.q1.parameters(), self.q1_target.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25808\\AppData\\Local\\Temp\\ipykernel_20540\\1165126909.py:112: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  state = torch.FloatTensor([state]).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode0:-1.01                         \n",
      "Episode0:1                             \n",
      "Episode10:-1.01                                \n",
      "Episode10:1                                    \n",
      "Episode20:-1.0253968698438256                  \n",
      "Episode20:25                                   \n",
      "Episode30:-0.9928214842826129                   \n",
      "Episode30:46                                    \n",
      "Episode40:-0.9635016041994096                   \n",
      "Episode40:3                                     \n",
      "Episode50:-1.0186003492958844                   \n",
      "Episode50:2                                     \n",
      "Episode60:-1.01                                 \n",
      "Episode60:1                                     \n",
      "Episode70:-1.01                                 \n",
      "Episode70:1                                     \n",
      "Episode80:-1.01                                 \n",
      "Episode80:1                                     \n",
      "Episode90:0.046909764111042036                  \n",
      "Episode90:73                                    \n",
      "Episode100:0.575544047653675                    \n",
      "Episode100:22                                   \n",
      "Episode110:0.6393116591870787                    \n",
      "Episode110:14                                    \n",
      "Episode120:0.6191941308975222                    \n",
      "Episode120:12                                    \n",
      "Episode130:0.7031225299835205                    \n",
      "Episode130:9                                     \n",
      "Episode140:0.6436460673809052                    \n",
      "Episode140:10                                    \n",
      "Episode150:0.6456427097320558                    \n",
      "Episode150:10                                    \n",
      "Episode160:0.6439654022455215                    \n",
      "Episode160:10                                    \n",
      "Episode170:0.6041597002744675                    \n",
      "Episode170:11                                    \n",
      "Episode180:0.6229614794254305                    \n",
      "Episode180:10                                    \n",
      "Episode190:0.6376704573631288                    \n",
      "Episode190:10                                    \n",
      "Episode200:0.7082898652553559                    \n",
      "Episode200:9                                     \n",
      "Episode210:0.6644763982295993                    \n",
      "Episode210:9                                     \n",
      "Episode220:0.7084483122825624                    \n",
      "Episode220:9                                     \n",
      "Episode230:0.6912602281570435                    \n",
      "Episode230:9                                     \n",
      "Episode240:0.643389305472374                     \n",
      "Episode240:10                                    \n",
      "Episode250:0.6769573122262956                    \n",
      "Episode250:10                                    \n",
      "Episode260:0.6899547016620636                    \n",
      "Episode260:9                                     \n",
      "Episode270:0.6623891448974611                    \n",
      "Episode270:9                                     \n",
      "Episode280:0.7096013641357423                    \n",
      "Episode280:9                                     \n",
      "Episode290:0.705138156414032                     \n",
      "Episode290:9                                     \n",
      "Episode300:0.7032854473590852                    \n",
      "Episode300:9                                     \n",
      "Episode310:0.6840892350673677                    \n",
      "Episode310:9                                     \n",
      "Episode320:0.6916843986511234                    \n",
      "Episode320:9                                     \n",
      "Episode330:0.6957969531416892                    \n",
      "Episode330:10                                    \n",
      "Episode340:0.6865169987082484                    \n",
      "Episode340:10                                    \n",
      "Episode350:0.7044116935133935                    \n",
      "Episode350:9                                     \n",
      "Episode360:0.694480404853821                     \n",
      "Episode360:9                                     \n",
      "Episode370:0.6696956932544711                    \n",
      "Episode370:10                                    \n",
      "Episode380:0.6903997337818147                    \n",
      "Episode380:9                                     \n",
      "Episode390:0.6655983264371753                    \n",
      "Episode390:13                                    \n",
      "Episode400:0.702749011516571                     \n",
      "Episode400:9                                     \n",
      "Episode410:0.7001587277650834                    \n",
      "Episode410:9                                     \n",
      "Episode420:0.6813247001171113                    \n",
      "Episode420:9                                     \n",
      "Episode430:0.6986904954910279                    \n",
      "Episode430:9                                     \n",
      "Episode440:0.7090999460220337                    \n",
      "Episode440:9                                     \n",
      "Episode450:0.68212730884552                      \n",
      "Episode450:10                                    \n",
      "Episode460:0.6898394262790681                    \n",
      "Episode460:9                                     \n",
      "Episode470:0.6751401042938235                    \n",
      "Episode470:9                                     \n",
      "Episode480:0.7058689570426943                    \n",
      "Episode480:9                                     \n",
      "Episode490:0.7072699046134949                    \n",
      "Episode490:9                                     \n",
      "100%|██████████| 500/500 [01:23<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "max_episodes = 500 # 迭代训练次数\n",
    "max_steps = 100    # 每个回合的最大步数\n",
    "\n",
    "# 创建对象\n",
    "agent = SAC(env, features_dim=2, action_dim=1)\n",
    "episode_rewards = []    # 只是用来看学习的成果的，和训练过程无关\n",
    "episode_steps = []\n",
    "\n",
    "# 开始迭代训练\n",
    "for episode in tqdm(range(max_episodes), file=sys.stdout):\n",
    "    # 重置环境并获取初始状态\n",
    "    state = env.reset()\n",
    "    # 初始化当前回合的奖励\n",
    "    episode_reward = 0\n",
    "    episode_step = 0\n",
    "    # 循环惊醒每一步的操作\n",
    "    for step in range(max_steps):\n",
    "        # 根据当前状态选择动作\n",
    "        action = agent.choose_action(state)\n",
    "        next_state, reward, terminated, truncated = env.step(action)  # 与环境交互产生下一个状态并生成奖励等相关信息\n",
    "        done = terminated or truncated\n",
    "        # 存入经验回放缓冲区\n",
    "        agent.store(state, reward, done, action, next_state)\n",
    "        agent.train()\n",
    "        episode_reward += reward\n",
    "        episode_step += 1\n",
    "        # 更新当前状态\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    # 记录当前回合的奖励\n",
    "    episode_rewards.append(episode_reward)\n",
    "    episode_steps.append(episode_step)\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "        tqdm.write(\"Episode\"+str(episode)+\":\"+str(episode_reward))\n",
    "        tqdm.write(\"Episode\"+str(episode)+\":\"+str(episode_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_list = []\n",
    "a_list = []\n",
    "for i in range(2000):\n",
    "    state = i / 1000 - 1\n",
    "    action = agent.eval_action([state, state])\n",
    "    s_list.append(state)\n",
    "    a_list.append(action[0][0])\n",
    "\n",
    "plt.plot(s_list, a_list)\n",
    "index_0_8 = s_list.index(0.8)\n",
    "a = a_list[index_0_8]\n",
    "plt.scatter([0.8], [a], color='red')\n",
    "plt.text(0.8, a, f'({0.8}, {a:.2f})', fontsize=12, verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
